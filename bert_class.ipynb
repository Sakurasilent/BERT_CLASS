{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"F:\\\\code\\self\\\\bert_class\\data\\æ„å›¾è¯†åˆ«æ ‡ç­¾.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\49262\\miniconda3\\envs\\bertv01\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>æ–‡æ¡ˆæ’°å†™</th>\n",
       "      <th>IDK</th>\n",
       "      <th>å“ç‰Œè¥é”€å’¨è¯¢</th>\n",
       "      <th>è¡Œä¸šè¥é”€å’¨è¯¢</th>\n",
       "      <th>è¾¾äººè¥é”€å’¨è¯¢</th>\n",
       "      <th>è¥é”€æ–‡æ¡ˆæ’°å†™</th>\n",
       "      <th>ä¸Šä¸€è½®æ„å›¾</th>\n",
       "      <th>å›¾æ¨¡æ€æ„å›¾</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. æˆ‘ä»¬æ–°å¼€äº†ä¸€å®¶å’–å•¡é¦†ï¼Œéœ€è¦æ’°å†™ä¸€æ®µå¸å¼•äººçš„å®£ä¼ æ–‡æ¡ˆã€‚</td>\n",
       "      <td>1. ä½ èƒ½å‘Šè¯‰æˆ‘XXXçš„å†…éƒ¨è´¢åŠ¡æŠ¥å‘Šå—ï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰</td>\n",
       "      <td>1. è‹¹æœå…¬å¸åœ¨2024å¹´çš„ç¬¬ä¸€å­£åº¦è¥é”€æ´»åŠ¨æ•ˆæœå¦‚ä½•ï¼Ÿ</td>\n",
       "      <td>1. 2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œæ±½è½¦è¡Œä¸šçš„è¥é”€æ´»åŠ¨æœ‰å“ªäº›äº®ç‚¹ï¼Ÿ</td>\n",
       "      <td>â€œæ‰“å·¥äººå—å—â€è¾¾äººè¿‘90å¤©çš„å‘æ–‡é‡æ˜¯å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>1. æˆ‘ä»¬å³å°†æ¨å‡ºä¸€æ¬¾æ–°çš„å¥åº·é¥®å“ï¼Œéœ€è¦æ’°å†™ä¸€ä¸ªå¸å¼•äººçš„äº§å“ç®€ä»‹ã€‚</td>\n",
       "      <td>èƒ½å¦å†æ·±å…¥æ¢è®¨ä¸€ä¸‹è¿™ä¸ªè¯é¢˜ï¼Ÿ</td>\n",
       "      <td>è¯·ç”Ÿæˆä¸€å¼ å°æœ‰â€œåŠ æ²¹ä¸­å›½â€çš„åŠ±å¿—æµ·æŠ¥ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. æˆ‘éœ€è¦ä¸ºå³å°†åˆ°æ¥çš„æ˜¥å­£ä¿ƒé”€æ´»åŠ¨å†™ä¸€ä¸ªæ´»åŠ¨sloganã€‚</td>\n",
       "      <td>2. è¯·é—®XXXçš„ä¸ªäººé‚®ç®±åœ°å€æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰</td>\n",
       "      <td>2. åä¸ºæ‰‹æœºåœ¨å¹´è½»æ¶ˆè´¹ç¾¤ä½“ä¸­çš„å—æ¬¢è¿ç¨‹åº¦æ˜¯æ€æ ·çš„ï¼Ÿ</td>\n",
       "      <td>2. å®¶ç”µè¡Œä¸šåœ¨2023å¹´çš„å¸‚åœºä»½é¢å˜åŒ–æ˜¯æ€æ ·çš„ï¼Ÿ</td>\n",
       "      <td>è¾¾äºº\"æ™¨æ™¨ğŸ°\"çš„äº’åŠ¨é‡æ€ä¹ˆæ ·ï¼Ÿ</td>\n",
       "      <td>2. æˆ‘æƒ³ä¸ºå³å°†åˆ°æ¥çš„æƒ…äººèŠ‚ç­–åˆ’ä¸€åœºçº¿ä¸Šæ´»åŠ¨ï¼Œä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªæ´»åŠ¨ä¸»é¢˜å—ï¼Ÿ</td>\n",
       "      <td>è¯·ç»§ç»­æ‰©å±•ä¹‹å‰çš„è®¨è®ºã€‚</td>\n",
       "      <td>èƒ½å¦åˆ¶ä½œä¸€å¼ åŒ…å«ä¸­å›½å›½æ——çš„è‰ºæœ¯æ’å›¾ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„æ ‡é¢˜ç”¨äºæˆ‘ä»¬çš„æ–°äº§å“å‘å¸ƒä¼šå—ï¼Ÿ</td>\n",
       "      <td>3. èƒ½å¦æä¾›æˆ‘ä»¬å…¬å¸æ‰€æœ‰å®¢æˆ·çš„è¯¦ç»†æ•°æ®ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰</td>\n",
       "      <td>3. èŒ…å°é…’åœ¨æµ·å¤–å¸‚åœºçš„å“ç‰Œå½±å“åŠ›å¦‚ä½•ï¼Ÿ</td>\n",
       "      <td>3. 2024å¹´ç¬¬äºŒå­£åº¦ï¼ŒåŒ–å¦†å“è¡Œä¸šçš„é”€å”®é¢å¢é•¿äº†å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>è¾¾äººâ€œè¶£å¤šå¤šçš„é€—å·â€è¿‘7å¤©çš„äº’åŠ¨é‡æ˜¯å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>3. æˆ‘éœ€è¦ä¸€ä»½PPTå¤§çº²ï¼Œå…³äºæˆ‘ä»¬å…¬å¸çš„å¹´åº¦æŠ¥å‘Šã€‚</td>\n",
       "      <td>ä½ èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹åˆšæ‰æåˆ°çš„å†…å®¹å—ï¼Ÿ</td>\n",
       "      <td>è¯·å¸®æˆ‘è®¾è®¡ä¸€ä¸ªä»¥â€œæ˜¥å¤©â€ä¸ºä¸»é¢˜çš„å›¾ç‰‡ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. æˆ‘æ­£åœ¨ç­¹å¤‡ä¸€ä¸ªçº¿ä¸Šç ”è®¨ä¼šï¼Œéœ€è¦ä¸€ä¸ªPPTå¤§çº²ã€‚</td>\n",
       "      <td>4. ä½ èƒ½æŸ¥è¯¢åˆ°XXXçš„å®Œæ•´å®¢æˆ·åå•å—ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰</td>\n",
       "      <td>4. è€å…‹å“ç‰Œåœ¨2024å¹´çš„è¥é”€ç­–ç•¥æœ‰å“ªäº›å˜åŒ–ï¼Ÿ</td>\n",
       "      <td>4. è¿‘ä¸‰ä¸ªæœˆå†…ï¼Œæœè£…è¡Œä¸šçš„æ¶ˆè´¹è€…æ»¡æ„åº¦è°ƒæŸ¥ç»“æœå¦‚ä½•ï¼Ÿ</td>\n",
       "      <td>è¾¾äºº\"ä¸é½èˆå›¢\"æœ€è¿‘å‘å¸ƒäº†å¤šå°‘å›¾æ–‡å†…å®¹ï¼Ÿ</td>\n",
       "      <td>4. ä½ èƒ½å¸®æˆ‘å†™ä¸€ç¯‡å…³äºç¯ä¿çš„æ–‡ç« å—ï¼Ÿ</td>\n",
       "      <td>èƒ½å¦åˆ†äº«æ›´å¤šç›¸å…³çš„ä¾‹å­ï¼Ÿ</td>\n",
       "      <td>èƒ½å¦ç”Ÿæˆä¸€å¼ æç»˜ä¸­å›½å±±æ°´ç”»é£æ ¼çš„å›¾åƒï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. æˆ‘ä»¬å…¬å¸å³å°†å‘å¸ƒä¸€æ¬¾æ–°çš„å¥åº·é¥®å“ï¼Œä½ èƒ½å¸®æˆ‘å†™ä¸€ç¯‡ç§è‰æ–‡æ¡ˆå—ï¼Ÿ</td>\n",
       "      <td>5. è¯·æä¾›XXXçš„å®Œæ•´æ•°æ®åº“è®¿é—®æƒé™ã€‚ï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰</td>\n",
       "      <td>5. æ˜Ÿå·´å…‹åœ¨ç¤¾äº¤åª’ä½“ä¸Šçš„äº’åŠ¨é‡æœ‰å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>5. 2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œé£Ÿå“è¡Œä¸šçš„è¥é”€ç­–ç•¥æœ‰å“ªäº›åˆ›æ–°ï¼Ÿ</td>\n",
       "      <td>è¾¾äººâ€œæ´è§â€çš„å›¾æ–‡æ•°æœ‰å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>5. æˆ‘éœ€è¦ä¸€ä»½æ‹›è˜ç­–åˆ’ï¼Œç”¨äºå¸å¼•ä¼˜ç§€çš„å¸‚åœºè¥é”€äººæ‰ã€‚</td>\n",
       "      <td>æˆ‘æƒ³çŸ¥é“æ›´å¤šå…³äºè¿™ä¸ªçš„ç»†èŠ‚ã€‚</td>\n",
       "      <td>è¯·åˆ¶ä½œä¸€å¼ åŒ…å«é•¿åŸå’Œå¤§ç†ŠçŒ«çš„æ’ç”»ã€‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                æ–‡æ¡ˆæ’°å†™                             IDK  \\\n",
       "0      1. æˆ‘ä»¬æ–°å¼€äº†ä¸€å®¶å’–å•¡é¦†ï¼Œéœ€è¦æ’°å†™ä¸€æ®µå¸å¼•äººçš„å®£ä¼ æ–‡æ¡ˆã€‚   1. ä½ èƒ½å‘Šè¯‰æˆ‘XXXçš„å†…éƒ¨è´¢åŠ¡æŠ¥å‘Šå—ï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰   \n",
       "1     2. æˆ‘éœ€è¦ä¸ºå³å°†åˆ°æ¥çš„æ˜¥å­£ä¿ƒé”€æ´»åŠ¨å†™ä¸€ä¸ªæ´»åŠ¨sloganã€‚    2. è¯·é—®XXXçš„ä¸ªäººé‚®ç®±åœ°å€æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰   \n",
       "2       3. ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„æ ‡é¢˜ç”¨äºæˆ‘ä»¬çš„æ–°äº§å“å‘å¸ƒä¼šå—ï¼Ÿ  3. èƒ½å¦æä¾›æˆ‘ä»¬å…¬å¸æ‰€æœ‰å®¢æˆ·çš„è¯¦ç»†æ•°æ®ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰   \n",
       "3         4. æˆ‘æ­£åœ¨ç­¹å¤‡ä¸€ä¸ªçº¿ä¸Šç ”è®¨ä¼šï¼Œéœ€è¦ä¸€ä¸ªPPTå¤§çº²ã€‚   4. ä½ èƒ½æŸ¥è¯¢åˆ°XXXçš„å®Œæ•´å®¢æˆ·åå•å—ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰   \n",
       "4  5. æˆ‘ä»¬å…¬å¸å³å°†å‘å¸ƒä¸€æ¬¾æ–°çš„å¥åº·é¥®å“ï¼Œä½ èƒ½å¸®æˆ‘å†™ä¸€ç¯‡ç§è‰æ–‡æ¡ˆå—ï¼Ÿ   5. è¯·æä¾›XXXçš„å®Œæ•´æ•°æ®åº“è®¿é—®æƒé™ã€‚ï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰   \n",
       "\n",
       "                        å“ç‰Œè¥é”€å’¨è¯¢                        è¡Œä¸šè¥é”€å’¨è¯¢  \\\n",
       "0  1. è‹¹æœå…¬å¸åœ¨2024å¹´çš„ç¬¬ä¸€å­£åº¦è¥é”€æ´»åŠ¨æ•ˆæœå¦‚ä½•ï¼Ÿ  1. 2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œæ±½è½¦è¡Œä¸šçš„è¥é”€æ´»åŠ¨æœ‰å“ªäº›äº®ç‚¹ï¼Ÿ   \n",
       "1   2. åä¸ºæ‰‹æœºåœ¨å¹´è½»æ¶ˆè´¹ç¾¤ä½“ä¸­çš„å—æ¬¢è¿ç¨‹åº¦æ˜¯æ€æ ·çš„ï¼Ÿ     2. å®¶ç”µè¡Œä¸šåœ¨2023å¹´çš„å¸‚åœºä»½é¢å˜åŒ–æ˜¯æ€æ ·çš„ï¼Ÿ   \n",
       "2         3. èŒ…å°é…’åœ¨æµ·å¤–å¸‚åœºçš„å“ç‰Œå½±å“åŠ›å¦‚ä½•ï¼Ÿ  3. 2024å¹´ç¬¬äºŒå­£åº¦ï¼ŒåŒ–å¦†å“è¡Œä¸šçš„é”€å”®é¢å¢é•¿äº†å¤šå°‘ï¼Ÿ   \n",
       "3     4. è€å…‹å“ç‰Œåœ¨2024å¹´çš„è¥é”€ç­–ç•¥æœ‰å“ªäº›å˜åŒ–ï¼Ÿ   4. è¿‘ä¸‰ä¸ªæœˆå†…ï¼Œæœè£…è¡Œä¸šçš„æ¶ˆè´¹è€…æ»¡æ„åº¦è°ƒæŸ¥ç»“æœå¦‚ä½•ï¼Ÿ   \n",
       "4         5. æ˜Ÿå·´å…‹åœ¨ç¤¾äº¤åª’ä½“ä¸Šçš„äº’åŠ¨é‡æœ‰å¤šå°‘ï¼Ÿ  5. 2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œé£Ÿå“è¡Œä¸šçš„è¥é”€ç­–ç•¥æœ‰å“ªäº›åˆ›æ–°ï¼Ÿ   \n",
       "\n",
       "                  è¾¾äººè¥é”€å’¨è¯¢                                è¥é”€æ–‡æ¡ˆæ’°å†™  \\\n",
       "0  â€œæ‰“å·¥äººå—å—â€è¾¾äººè¿‘90å¤©çš„å‘æ–‡é‡æ˜¯å¤šå°‘ï¼Ÿ     1. æˆ‘ä»¬å³å°†æ¨å‡ºä¸€æ¬¾æ–°çš„å¥åº·é¥®å“ï¼Œéœ€è¦æ’°å†™ä¸€ä¸ªå¸å¼•äººçš„äº§å“ç®€ä»‹ã€‚   \n",
       "1        è¾¾äºº\"æ™¨æ™¨ğŸ°\"çš„äº’åŠ¨é‡æ€ä¹ˆæ ·ï¼Ÿ  2. æˆ‘æƒ³ä¸ºå³å°†åˆ°æ¥çš„æƒ…äººèŠ‚ç­–åˆ’ä¸€åœºçº¿ä¸Šæ´»åŠ¨ï¼Œä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªæ´»åŠ¨ä¸»é¢˜å—ï¼Ÿ   \n",
       "2  è¾¾äººâ€œè¶£å¤šå¤šçš„é€—å·â€è¿‘7å¤©çš„äº’åŠ¨é‡æ˜¯å¤šå°‘ï¼Ÿ            3. æˆ‘éœ€è¦ä¸€ä»½PPTå¤§çº²ï¼Œå…³äºæˆ‘ä»¬å…¬å¸çš„å¹´åº¦æŠ¥å‘Šã€‚   \n",
       "3   è¾¾äºº\"ä¸é½èˆå›¢\"æœ€è¿‘å‘å¸ƒäº†å¤šå°‘å›¾æ–‡å†…å®¹ï¼Ÿ                   4. ä½ èƒ½å¸®æˆ‘å†™ä¸€ç¯‡å…³äºç¯ä¿çš„æ–‡ç« å—ï¼Ÿ   \n",
       "4         è¾¾äººâ€œæ´è§â€çš„å›¾æ–‡æ•°æœ‰å¤šå°‘ï¼Ÿ           5. æˆ‘éœ€è¦ä¸€ä»½æ‹›è˜ç­–åˆ’ï¼Œç”¨äºå¸å¼•ä¼˜ç§€çš„å¸‚åœºè¥é”€äººæ‰ã€‚   \n",
       "\n",
       "               ä¸Šä¸€è½®æ„å›¾                å›¾æ¨¡æ€æ„å›¾  \n",
       "0     èƒ½å¦å†æ·±å…¥æ¢è®¨ä¸€ä¸‹è¿™ä¸ªè¯é¢˜ï¼Ÿ  è¯·ç”Ÿæˆä¸€å¼ å°æœ‰â€œåŠ æ²¹ä¸­å›½â€çš„åŠ±å¿—æµ·æŠ¥ã€‚  \n",
       "1        è¯·ç»§ç»­æ‰©å±•ä¹‹å‰çš„è®¨è®ºã€‚   èƒ½å¦åˆ¶ä½œä¸€å¼ åŒ…å«ä¸­å›½å›½æ——çš„è‰ºæœ¯æ’å›¾ï¼Ÿ  \n",
       "2  ä½ èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹åˆšæ‰æåˆ°çš„å†…å®¹å—ï¼Ÿ  è¯·å¸®æˆ‘è®¾è®¡ä¸€ä¸ªä»¥â€œæ˜¥å¤©â€ä¸ºä¸»é¢˜çš„å›¾ç‰‡ã€‚  \n",
       "3       èƒ½å¦åˆ†äº«æ›´å¤šç›¸å…³çš„ä¾‹å­ï¼Ÿ  èƒ½å¦ç”Ÿæˆä¸€å¼ æç»˜ä¸­å›½å±±æ°´ç”»é£æ ¼çš„å›¾åƒï¼Ÿ  \n",
       "4     æˆ‘æƒ³çŸ¥é“æ›´å¤šå…³äºè¿™ä¸ªçš„ç»†èŠ‚ã€‚    è¯·åˆ¶ä½œä¸€å¼ åŒ…å«é•¿åŸå’Œå¤§ç†ŠçŒ«çš„æ’ç”»ã€‚  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49262\\AppData\\Local\\Temp\\ipykernel_2332\\3781330178.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(lambda x: x.split(\". \")[-1] if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "data = data.applymap(lambda x: x.split(\". \")[-1] if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>æ–‡æ¡ˆæ’°å†™</th>\n",
       "      <th>IDK</th>\n",
       "      <th>å“ç‰Œè¥é”€å’¨è¯¢</th>\n",
       "      <th>è¡Œä¸šè¥é”€å’¨è¯¢</th>\n",
       "      <th>è¾¾äººè¥é”€å’¨è¯¢</th>\n",
       "      <th>è¥é”€æ–‡æ¡ˆæ’°å†™</th>\n",
       "      <th>ä¸Šä¸€è½®æ„å›¾</th>\n",
       "      <th>å›¾æ¨¡æ€æ„å›¾</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æˆ‘ä»¬æ–°å¼€äº†ä¸€å®¶å’–å•¡é¦†ï¼Œéœ€è¦æ’°å†™ä¸€æ®µå¸å¼•äººçš„å®£ä¼ æ–‡æ¡ˆã€‚</td>\n",
       "      <td>ä½ èƒ½å‘Šè¯‰æˆ‘XXXçš„å†…éƒ¨è´¢åŠ¡æŠ¥å‘Šå—ï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰</td>\n",
       "      <td>è‹¹æœå…¬å¸åœ¨2024å¹´çš„ç¬¬ä¸€å­£åº¦è¥é”€æ´»åŠ¨æ•ˆæœå¦‚ä½•ï¼Ÿ</td>\n",
       "      <td>2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œæ±½è½¦è¡Œä¸šçš„è¥é”€æ´»åŠ¨æœ‰å“ªäº›äº®ç‚¹ï¼Ÿ</td>\n",
       "      <td>â€œæ‰“å·¥äººå—å—â€è¾¾äººè¿‘90å¤©çš„å‘æ–‡é‡æ˜¯å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>æˆ‘ä»¬å³å°†æ¨å‡ºä¸€æ¬¾æ–°çš„å¥åº·é¥®å“ï¼Œéœ€è¦æ’°å†™ä¸€ä¸ªå¸å¼•äººçš„äº§å“ç®€ä»‹ã€‚</td>\n",
       "      <td>èƒ½å¦å†æ·±å…¥æ¢è®¨ä¸€ä¸‹è¿™ä¸ªè¯é¢˜ï¼Ÿ</td>\n",
       "      <td>è¯·ç”Ÿæˆä¸€å¼ å°æœ‰â€œåŠ æ²¹ä¸­å›½â€çš„åŠ±å¿—æµ·æŠ¥ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>æˆ‘éœ€è¦ä¸ºå³å°†åˆ°æ¥çš„æ˜¥å­£ä¿ƒé”€æ´»åŠ¨å†™ä¸€ä¸ªæ´»åŠ¨sloganã€‚</td>\n",
       "      <td>è¯·é—®XXXçš„ä¸ªäººé‚®ç®±åœ°å€æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰</td>\n",
       "      <td>åä¸ºæ‰‹æœºåœ¨å¹´è½»æ¶ˆè´¹ç¾¤ä½“ä¸­çš„å—æ¬¢è¿ç¨‹åº¦æ˜¯æ€æ ·çš„ï¼Ÿ</td>\n",
       "      <td>å®¶ç”µè¡Œä¸šåœ¨2023å¹´çš„å¸‚åœºä»½é¢å˜åŒ–æ˜¯æ€æ ·çš„ï¼Ÿ</td>\n",
       "      <td>è¾¾äºº\"æ™¨æ™¨ğŸ°\"çš„äº’åŠ¨é‡æ€ä¹ˆæ ·ï¼Ÿ</td>\n",
       "      <td>æˆ‘æƒ³ä¸ºå³å°†åˆ°æ¥çš„æƒ…äººèŠ‚ç­–åˆ’ä¸€åœºçº¿ä¸Šæ´»åŠ¨ï¼Œä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªæ´»åŠ¨ä¸»é¢˜å—ï¼Ÿ</td>\n",
       "      <td>è¯·ç»§ç»­æ‰©å±•ä¹‹å‰çš„è®¨è®ºã€‚</td>\n",
       "      <td>èƒ½å¦åˆ¶ä½œä¸€å¼ åŒ…å«ä¸­å›½å›½æ——çš„è‰ºæœ¯æ’å›¾ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„æ ‡é¢˜ç”¨äºæˆ‘ä»¬çš„æ–°äº§å“å‘å¸ƒä¼šå—ï¼Ÿ</td>\n",
       "      <td>èƒ½å¦æä¾›æˆ‘ä»¬å…¬å¸æ‰€æœ‰å®¢æˆ·çš„è¯¦ç»†æ•°æ®ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰</td>\n",
       "      <td>èŒ…å°é…’åœ¨æµ·å¤–å¸‚åœºçš„å“ç‰Œå½±å“åŠ›å¦‚ä½•ï¼Ÿ</td>\n",
       "      <td>2024å¹´ç¬¬äºŒå­£åº¦ï¼ŒåŒ–å¦†å“è¡Œä¸šçš„é”€å”®é¢å¢é•¿äº†å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>è¾¾äººâ€œè¶£å¤šå¤šçš„é€—å·â€è¿‘7å¤©çš„äº’åŠ¨é‡æ˜¯å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>æˆ‘éœ€è¦ä¸€ä»½PPTå¤§çº²ï¼Œå…³äºæˆ‘ä»¬å…¬å¸çš„å¹´åº¦æŠ¥å‘Šã€‚</td>\n",
       "      <td>ä½ èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹åˆšæ‰æåˆ°çš„å†…å®¹å—ï¼Ÿ</td>\n",
       "      <td>è¯·å¸®æˆ‘è®¾è®¡ä¸€ä¸ªä»¥â€œæ˜¥å¤©â€ä¸ºä¸»é¢˜çš„å›¾ç‰‡ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>æˆ‘æ­£åœ¨ç­¹å¤‡ä¸€ä¸ªçº¿ä¸Šç ”è®¨ä¼šï¼Œéœ€è¦ä¸€ä¸ªPPTå¤§çº²ã€‚</td>\n",
       "      <td>ä½ èƒ½æŸ¥è¯¢åˆ°XXXçš„å®Œæ•´å®¢æˆ·åå•å—ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰</td>\n",
       "      <td>è€å…‹å“ç‰Œåœ¨2024å¹´çš„è¥é”€ç­–ç•¥æœ‰å“ªäº›å˜åŒ–ï¼Ÿ</td>\n",
       "      <td>è¿‘ä¸‰ä¸ªæœˆå†…ï¼Œæœè£…è¡Œä¸šçš„æ¶ˆè´¹è€…æ»¡æ„åº¦è°ƒæŸ¥ç»“æœå¦‚ä½•ï¼Ÿ</td>\n",
       "      <td>è¾¾äºº\"ä¸é½èˆå›¢\"æœ€è¿‘å‘å¸ƒäº†å¤šå°‘å›¾æ–‡å†…å®¹ï¼Ÿ</td>\n",
       "      <td>ä½ èƒ½å¸®æˆ‘å†™ä¸€ç¯‡å…³äºç¯ä¿çš„æ–‡ç« å—ï¼Ÿ</td>\n",
       "      <td>èƒ½å¦åˆ†äº«æ›´å¤šç›¸å…³çš„ä¾‹å­ï¼Ÿ</td>\n",
       "      <td>èƒ½å¦ç”Ÿæˆä¸€å¼ æç»˜ä¸­å›½å±±æ°´ç”»é£æ ¼çš„å›¾åƒï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>æˆ‘ä»¬å…¬å¸å³å°†å‘å¸ƒä¸€æ¬¾æ–°çš„å¥åº·é¥®å“ï¼Œä½ èƒ½å¸®æˆ‘å†™ä¸€ç¯‡ç§è‰æ–‡æ¡ˆå—ï¼Ÿ</td>\n",
       "      <td>è¯·æä¾›XXXçš„å®Œæ•´æ•°æ®åº“è®¿é—®æƒé™ã€‚ï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰</td>\n",
       "      <td>æ˜Ÿå·´å…‹åœ¨ç¤¾äº¤åª’ä½“ä¸Šçš„äº’åŠ¨é‡æœ‰å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œé£Ÿå“è¡Œä¸šçš„è¥é”€ç­–ç•¥æœ‰å“ªäº›åˆ›æ–°ï¼Ÿ</td>\n",
       "      <td>è¾¾äººâ€œæ´è§â€çš„å›¾æ–‡æ•°æœ‰å¤šå°‘ï¼Ÿ</td>\n",
       "      <td>æˆ‘éœ€è¦ä¸€ä»½æ‹›è˜ç­–åˆ’ï¼Œç”¨äºå¸å¼•ä¼˜ç§€çš„å¸‚åœºè¥é”€äººæ‰ã€‚</td>\n",
       "      <td>æˆ‘æƒ³çŸ¥é“æ›´å¤šå…³äºè¿™ä¸ªçš„ç»†èŠ‚ã€‚</td>\n",
       "      <td>è¯·åˆ¶ä½œä¸€å¼ åŒ…å«é•¿åŸå’Œå¤§ç†ŠçŒ«çš„æ’ç”»ã€‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             æ–‡æ¡ˆæ’°å†™                          IDK  \\\n",
       "0      æˆ‘ä»¬æ–°å¼€äº†ä¸€å®¶å’–å•¡é¦†ï¼Œéœ€è¦æ’°å†™ä¸€æ®µå¸å¼•äººçš„å®£ä¼ æ–‡æ¡ˆã€‚   ä½ èƒ½å‘Šè¯‰æˆ‘XXXçš„å†…éƒ¨è´¢åŠ¡æŠ¥å‘Šå—ï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰   \n",
       "1     æˆ‘éœ€è¦ä¸ºå³å°†åˆ°æ¥çš„æ˜¥å­£ä¿ƒé”€æ´»åŠ¨å†™ä¸€ä¸ªæ´»åŠ¨sloganã€‚    è¯·é—®XXXçš„ä¸ªäººé‚®ç®±åœ°å€æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰   \n",
       "2       ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„æ ‡é¢˜ç”¨äºæˆ‘ä»¬çš„æ–°äº§å“å‘å¸ƒä¼šå—ï¼Ÿ  èƒ½å¦æä¾›æˆ‘ä»¬å…¬å¸æ‰€æœ‰å®¢æˆ·çš„è¯¦ç»†æ•°æ®ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰   \n",
       "3         æˆ‘æ­£åœ¨ç­¹å¤‡ä¸€ä¸ªçº¿ä¸Šç ”è®¨ä¼šï¼Œéœ€è¦ä¸€ä¸ªPPTå¤§çº²ã€‚   ä½ èƒ½æŸ¥è¯¢åˆ°XXXçš„å®Œæ•´å®¢æˆ·åå•å—ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰   \n",
       "4  æˆ‘ä»¬å…¬å¸å³å°†å‘å¸ƒä¸€æ¬¾æ–°çš„å¥åº·é¥®å“ï¼Œä½ èƒ½å¸®æˆ‘å†™ä¸€ç¯‡ç§è‰æ–‡æ¡ˆå—ï¼Ÿ   è¯·æä¾›XXXçš„å®Œæ•´æ•°æ®åº“è®¿é—®æƒé™ã€‚ï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰   \n",
       "\n",
       "                     å“ç‰Œè¥é”€å’¨è¯¢                     è¡Œä¸šè¥é”€å’¨è¯¢                 è¾¾äººè¥é”€å’¨è¯¢  \\\n",
       "0  è‹¹æœå…¬å¸åœ¨2024å¹´çš„ç¬¬ä¸€å­£åº¦è¥é”€æ´»åŠ¨æ•ˆæœå¦‚ä½•ï¼Ÿ  2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œæ±½è½¦è¡Œä¸šçš„è¥é”€æ´»åŠ¨æœ‰å“ªäº›äº®ç‚¹ï¼Ÿ  â€œæ‰“å·¥äººå—å—â€è¾¾äººè¿‘90å¤©çš„å‘æ–‡é‡æ˜¯å¤šå°‘ï¼Ÿ   \n",
       "1   åä¸ºæ‰‹æœºåœ¨å¹´è½»æ¶ˆè´¹ç¾¤ä½“ä¸­çš„å—æ¬¢è¿ç¨‹åº¦æ˜¯æ€æ ·çš„ï¼Ÿ     å®¶ç”µè¡Œä¸šåœ¨2023å¹´çš„å¸‚åœºä»½é¢å˜åŒ–æ˜¯æ€æ ·çš„ï¼Ÿ        è¾¾äºº\"æ™¨æ™¨ğŸ°\"çš„äº’åŠ¨é‡æ€ä¹ˆæ ·ï¼Ÿ   \n",
       "2         èŒ…å°é…’åœ¨æµ·å¤–å¸‚åœºçš„å“ç‰Œå½±å“åŠ›å¦‚ä½•ï¼Ÿ  2024å¹´ç¬¬äºŒå­£åº¦ï¼ŒåŒ–å¦†å“è¡Œä¸šçš„é”€å”®é¢å¢é•¿äº†å¤šå°‘ï¼Ÿ  è¾¾äººâ€œè¶£å¤šå¤šçš„é€—å·â€è¿‘7å¤©çš„äº’åŠ¨é‡æ˜¯å¤šå°‘ï¼Ÿ   \n",
       "3     è€å…‹å“ç‰Œåœ¨2024å¹´çš„è¥é”€ç­–ç•¥æœ‰å“ªäº›å˜åŒ–ï¼Ÿ   è¿‘ä¸‰ä¸ªæœˆå†…ï¼Œæœè£…è¡Œä¸šçš„æ¶ˆè´¹è€…æ»¡æ„åº¦è°ƒæŸ¥ç»“æœå¦‚ä½•ï¼Ÿ   è¾¾äºº\"ä¸é½èˆå›¢\"æœ€è¿‘å‘å¸ƒäº†å¤šå°‘å›¾æ–‡å†…å®¹ï¼Ÿ   \n",
       "4         æ˜Ÿå·´å…‹åœ¨ç¤¾äº¤åª’ä½“ä¸Šçš„äº’åŠ¨é‡æœ‰å¤šå°‘ï¼Ÿ  2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œé£Ÿå“è¡Œä¸šçš„è¥é”€ç­–ç•¥æœ‰å“ªäº›åˆ›æ–°ï¼Ÿ         è¾¾äººâ€œæ´è§â€çš„å›¾æ–‡æ•°æœ‰å¤šå°‘ï¼Ÿ   \n",
       "\n",
       "                              è¥é”€æ–‡æ¡ˆæ’°å†™              ä¸Šä¸€è½®æ„å›¾                å›¾æ¨¡æ€æ„å›¾  \n",
       "0     æˆ‘ä»¬å³å°†æ¨å‡ºä¸€æ¬¾æ–°çš„å¥åº·é¥®å“ï¼Œéœ€è¦æ’°å†™ä¸€ä¸ªå¸å¼•äººçš„äº§å“ç®€ä»‹ã€‚     èƒ½å¦å†æ·±å…¥æ¢è®¨ä¸€ä¸‹è¿™ä¸ªè¯é¢˜ï¼Ÿ  è¯·ç”Ÿæˆä¸€å¼ å°æœ‰â€œåŠ æ²¹ä¸­å›½â€çš„åŠ±å¿—æµ·æŠ¥ã€‚  \n",
       "1  æˆ‘æƒ³ä¸ºå³å°†åˆ°æ¥çš„æƒ…äººèŠ‚ç­–åˆ’ä¸€åœºçº¿ä¸Šæ´»åŠ¨ï¼Œä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªæ´»åŠ¨ä¸»é¢˜å—ï¼Ÿ        è¯·ç»§ç»­æ‰©å±•ä¹‹å‰çš„è®¨è®ºã€‚   èƒ½å¦åˆ¶ä½œä¸€å¼ åŒ…å«ä¸­å›½å›½æ——çš„è‰ºæœ¯æ’å›¾ï¼Ÿ  \n",
       "2            æˆ‘éœ€è¦ä¸€ä»½PPTå¤§çº²ï¼Œå…³äºæˆ‘ä»¬å…¬å¸çš„å¹´åº¦æŠ¥å‘Šã€‚  ä½ èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹åˆšæ‰æåˆ°çš„å†…å®¹å—ï¼Ÿ  è¯·å¸®æˆ‘è®¾è®¡ä¸€ä¸ªä»¥â€œæ˜¥å¤©â€ä¸ºä¸»é¢˜çš„å›¾ç‰‡ã€‚  \n",
       "3                   ä½ èƒ½å¸®æˆ‘å†™ä¸€ç¯‡å…³äºç¯ä¿çš„æ–‡ç« å—ï¼Ÿ       èƒ½å¦åˆ†äº«æ›´å¤šç›¸å…³çš„ä¾‹å­ï¼Ÿ  èƒ½å¦ç”Ÿæˆä¸€å¼ æç»˜ä¸­å›½å±±æ°´ç”»é£æ ¼çš„å›¾åƒï¼Ÿ  \n",
       "4           æˆ‘éœ€è¦ä¸€ä»½æ‹›è˜ç­–åˆ’ï¼Œç”¨äºå¸å¼•ä¼˜ç§€çš„å¸‚åœºè¥é”€äººæ‰ã€‚     æˆ‘æƒ³çŸ¥é“æ›´å¤šå…³äºè¿™ä¸ªçš„ç»†èŠ‚ã€‚    è¯·åˆ¶ä½œä¸€å¼ åŒ…å«é•¿åŸå’Œå¤§ç†ŠçŒ«çš„æ’ç”»ã€‚  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"intend.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['æ–‡æ¡ˆæ’°å†™', 'IDK', 'å“ç‰Œè¥é”€å’¨è¯¢', 'è¡Œä¸šè¥é”€å’¨è¯¢', 'è¾¾äººè¥é”€å’¨è¯¢', 'è¥é”€æ–‡æ¡ˆæ’°å†™', 'ä¸Šä¸€è½®æ„å›¾', 'å›¾æ¨¡æ€æ„å›¾']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data.columns.to_list()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=[\"label\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æ–‡æ¡ˆæ’°å†™</td>\n",
       "      <td>æˆ‘ä»¬æ–°å¼€äº†ä¸€å®¶å’–å•¡é¦†ï¼Œéœ€è¦æ’°å†™ä¸€æ®µå¸å¼•äººçš„å®£ä¼ æ–‡æ¡ˆã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDK</td>\n",
       "      <td>ä½ èƒ½å‘Šè¯‰æˆ‘XXXçš„å†…éƒ¨è´¢åŠ¡æŠ¥å‘Šå—ï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>å“ç‰Œè¥é”€å’¨è¯¢</td>\n",
       "      <td>è‹¹æœå…¬å¸åœ¨2024å¹´çš„ç¬¬ä¸€å­£åº¦è¥é”€æ´»åŠ¨æ•ˆæœå¦‚ä½•ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>è¡Œä¸šè¥é”€å’¨è¯¢</td>\n",
       "      <td>2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œæ±½è½¦è¡Œä¸šçš„è¥é”€æ´»åŠ¨æœ‰å“ªäº›äº®ç‚¹ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>è¾¾äººè¥é”€å’¨è¯¢</td>\n",
       "      <td>â€œæ‰“å·¥äººå—å—â€è¾¾äººè¿‘90å¤©çš„å‘æ–‡é‡æ˜¯å¤šå°‘ï¼Ÿ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                        text\n",
       "0    æ–‡æ¡ˆæ’°å†™  æˆ‘ä»¬æ–°å¼€äº†ä¸€å®¶å’–å•¡é¦†ï¼Œéœ€è¦æ’°å†™ä¸€æ®µå¸å¼•äººçš„å®£ä¼ æ–‡æ¡ˆã€‚\n",
       "1     IDK  ä½ èƒ½å‘Šè¯‰æˆ‘XXXçš„å†…éƒ¨è´¢åŠ¡æŠ¥å‘Šå—ï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰\n",
       "2  å“ç‰Œè¥é”€å’¨è¯¢    è‹¹æœå…¬å¸åœ¨2024å¹´çš„ç¬¬ä¸€å­£åº¦è¥é”€æ´»åŠ¨æ•ˆæœå¦‚ä½•ï¼Ÿ\n",
       "3  è¡Œä¸šè¥é”€å’¨è¯¢   2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œæ±½è½¦è¡Œä¸šçš„è¥é”€æ´»åŠ¨æœ‰å“ªäº›äº®ç‚¹ï¼Ÿ\n",
       "4  è¾¾äººè¥é”€å’¨è¯¢       â€œæ‰“å·¥äººå—å—â€è¾¾äººè¿‘90å¤©çš„å‘æ–‡é‡æ˜¯å¤šå°‘ï¼Ÿ"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in data.iterrows():\n",
    "    temp_data = []\n",
    "    for label, content in zip(labels, row.values):\n",
    "        if pd.notna(content) and content!=\"\":\n",
    "            temp_data.append({'label': label, 'text': content})\n",
    "    if temp_data:\n",
    "        temp_df = pd.DataFrame(temp_data)\n",
    "        result = pd.concat([result, temp_df], ignore_index=True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = result[\"text\"]\n",
    "Y = result[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    æˆ‘ä»¬æ–°å¼€äº†ä¸€å®¶å’–å•¡é¦†ï¼Œéœ€è¦æ’°å†™ä¸€æ®µå¸å¼•äººçš„å®£ä¼ æ–‡æ¡ˆã€‚\n",
       "1    ä½ èƒ½å‘Šè¯‰æˆ‘XXXçš„å†…éƒ¨è´¢åŠ¡æŠ¥å‘Šå—ï¼Ÿï¼ˆåŸå› ï¼šæ¶æ„æŸ¥è¯¢ï¼‰\n",
       "2      è‹¹æœå…¬å¸åœ¨2024å¹´çš„ç¬¬ä¸€å­£åº¦è¥é”€æ´»åŠ¨æ•ˆæœå¦‚ä½•ï¼Ÿ\n",
       "3     2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œæ±½è½¦è¡Œä¸šçš„è¥é”€æ´»åŠ¨æœ‰å“ªäº›äº®ç‚¹ï¼Ÿ\n",
       "4         â€œæ‰“å·¥äººå—å—â€è¾¾äººè¿‘90å¤©çš„å‘æ–‡é‡æ˜¯å¤šå°‘ï¼Ÿ\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      æ–‡æ¡ˆæ’°å†™\n",
       "1       IDK\n",
       "2    å“ç‰Œè¥é”€å’¨è¯¢\n",
       "3    è¡Œä¸šè¥é”€å’¨è¯¢\n",
       "4    è¾¾äººè¥é”€å’¨è¯¢\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"train.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\49262\\miniconda3\\envs\\bertv01\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:11: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.22.4)\n",
      "  from scipy.sparse import csr_matrix, issparse\n",
      "c:\\Users\\49262\\miniconda3\\envs\\bertv01\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, BertConfig\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'text'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(result, test_size=0.1, random_state=42, stratify=result['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>å“ç‰Œè¥é”€å’¨è¯¢</td>\n",
       "      <td>å¥¥è¿ªåœ¨ä¸­å›½å¸‚åœºçš„å“ç‰Œæ¨å¹¿æ´»åŠ¨æœ‰å“ªäº›ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>æ–‡æ¡ˆæ’°å†™</td>\n",
       "      <td>ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„å†…å®¹ç»­å†™å—ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>è¥é”€æ–‡æ¡ˆæ’°å†™</td>\n",
       "      <td>æˆ‘æƒ³å†™ä¸€ç¯‡å…³äºå¥åº·é¥®é£Ÿçš„æ–‡ç« ï¼Œèƒ½ç»™æˆ‘ä¸ªå¤§çº²å—ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>è¥é”€æ–‡æ¡ˆæ’°å†™</td>\n",
       "      <td>ä½ æœ‰å–œæ¬¢çš„è¿åŠ¨å—ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>æ–‡æ¡ˆæ’°å†™</td>\n",
       "      <td>ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„å¯¹è¯ç¼–æ’°å—ï¼Ÿ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                     text\n",
       "892   å“ç‰Œè¥é”€å’¨è¯¢       å¥¥è¿ªåœ¨ä¸­å›½å¸‚åœºçš„å“ç‰Œæ¨å¹¿æ´»åŠ¨æœ‰å“ªäº›ï¼Ÿ\n",
       "312     æ–‡æ¡ˆæ’°å†™         ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„å†…å®¹ç»­å†™å—ï¼Ÿ\n",
       "613   è¥é”€æ–‡æ¡ˆæ’°å†™  æˆ‘æƒ³å†™ä¸€ç¯‡å…³äºå¥åº·é¥®é£Ÿçš„æ–‡ç« ï¼Œèƒ½ç»™æˆ‘ä¸ªå¤§çº²å—ï¼Ÿ\n",
       "1039  è¥é”€æ–‡æ¡ˆæ’°å†™                ä½ æœ‰å–œæ¬¢çš„è¿åŠ¨å—ï¼Ÿ\n",
       "592     æ–‡æ¡ˆæ’°å†™         ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„å¯¹è¯ç¼–æ’°å—ï¼Ÿ"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>æ–‡æ¡ˆæ’°å†™</td>\n",
       "      <td>æˆ‘éœ€è¦ä¸ºä¸€æ¬¾æ–°çš„åŒ–å¦†å“æ’°å†™ä¸€ç¯‡æ–°é—»ç¨¿ä»¶ä¿®è®¢ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>è¾¾äººè¥é”€å’¨è¯¢</td>\n",
       "      <td>â€æ·±å¤œå¾è€å¸ˆâ€œè¾¾äººåœ¨å°çº¢ä¹¦å¹³å°ä¸Šæ˜¯å¦å—æ¬¢è¿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>æ–‡æ¡ˆæ’°å†™</td>\n",
       "      <td>ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„æ–°é—»ä¸“è®¿å—ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>å›¾æ¨¡æ€æ„å›¾</td>\n",
       "      <td>è¯·è®¾è®¡ä¸€å¼ ä»¥ä¸­å›½ç»æµå‘å±•çš„ä¸»é¢˜ä¸ºå›¾åƒã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>IDK</td>\n",
       "      <td>ç”²éª¨æ–‡åœ¨æœªæ¥ä¼šæ¨å‡ºå“ªäº›æ–°äº§å“ï¼Ÿï¼ˆåŸå› ï¼šæ¢ç´¢å“ç‰Œæœªæ¥äº§å“çº¿çš„å¯èƒ½æ€§ï¼‰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>å›¾æ¨¡æ€æ„å›¾</td>\n",
       "      <td>è¯·åˆ¶ä½œä¸€å¼ ä¸ä¸­å›½å¤ä»£æ–‡å­¦ä½œå“ç›¸å…³çš„å›¾åƒã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>è¡Œä¸šè¥é”€å’¨è¯¢</td>\n",
       "      <td>2024å¹´ç¬¬äºŒå­£åº¦ï¼ŒéŸ³ä¹è¡Œä¸šé¢ä¸´çš„ä¸»è¦è¥é”€æŒ‘æˆ˜æœ‰å“ªäº›ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>IDK</td>\n",
       "      <td>èƒ½å¦å…±äº«ä¸€ä¸‹å»å“ªå„¿ç½‘çš„ç”¨æˆ·æ»¡æ„åº¦è°ƒæŸ¥ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>IDK</td>\n",
       "      <td>æˆ‘æƒ³çŸ¥é“ç‰¹æ–¯æ‹‰çš„å‘˜å·¥è–ªèµ„èŒƒå›´ã€‚ï¼ˆåŸå› ï¼šéšç§ä¿¡æ¯ï¼‰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>ä¸Šä¸€è½®æ„å›¾</td>\n",
       "      <td>èƒ½å¦æä¾›è¿›ä¸€æ­¥çš„è§è§£ï¼Ÿ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                               text\n",
       "224    æ–‡æ¡ˆæ’°å†™             æˆ‘éœ€è¦ä¸ºä¸€æ¬¾æ–°çš„åŒ–å¦†å“æ’°å†™ä¸€ç¯‡æ–°é—»ç¨¿ä»¶ä¿®è®¢ã€‚\n",
       "748  è¾¾äººè¥é”€å’¨è¯¢              â€æ·±å¤œå¾è€å¸ˆâ€œè¾¾äººåœ¨å°çº¢ä¹¦å¹³å°ä¸Šæ˜¯å¦å—æ¬¢è¿\n",
       "344    æ–‡æ¡ˆæ’°å†™                   ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªåˆ›æ„çš„æ–°é—»ä¸“è®¿å—ï¼Ÿ\n",
       "495   å›¾æ¨¡æ€æ„å›¾                è¯·è®¾è®¡ä¸€å¼ ä»¥ä¸­å›½ç»æµå‘å±•çš„ä¸»é¢˜ä¸ºå›¾åƒã€‚\n",
       "569     IDK  ç”²éª¨æ–‡åœ¨æœªæ¥ä¼šæ¨å‡ºå“ªäº›æ–°äº§å“ï¼Ÿï¼ˆåŸå› ï¼šæ¢ç´¢å“ç‰Œæœªæ¥äº§å“çº¿çš„å¯èƒ½æ€§ï¼‰\n",
       "..      ...                                ...\n",
       "463   å›¾æ¨¡æ€æ„å›¾               è¯·åˆ¶ä½œä¸€å¼ ä¸ä¸­å›½å¤ä»£æ–‡å­¦ä½œå“ç›¸å…³çš„å›¾åƒã€‚\n",
       "739  è¡Œä¸šè¥é”€å’¨è¯¢        2024å¹´ç¬¬äºŒå­£åº¦ï¼ŒéŸ³ä¹è¡Œä¸šé¢ä¸´çš„ä¸»è¦è¥é”€æŒ‘æˆ˜æœ‰å“ªäº›ï¼Ÿ\n",
       "981     IDK       èƒ½å¦å…±äº«ä¸€ä¸‹å»å“ªå„¿ç½‘çš„ç”¨æˆ·æ»¡æ„åº¦è°ƒæŸ¥ï¼Ÿï¼ˆåŸå› ï¼šæ•°æ®æ¢åº•ï¼‰\n",
       "813     IDK           æˆ‘æƒ³çŸ¥é“ç‰¹æ–¯æ‹‰çš„å‘˜å·¥è–ªèµ„èŒƒå›´ã€‚ï¼ˆåŸå› ï¼šéšç§ä¿¡æ¯ï¼‰\n",
       "118   ä¸Šä¸€è½®æ„å›¾                        èƒ½å¦æä¾›è¿›ä¸€æ­¥çš„è§è§£ï¼Ÿ\n",
       "\n",
       "[113 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"F:/code/self/bert_class/hgmodel/bert_base_chinese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def encode_texts(texts, max_length):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'  # Change to 'pt' for PyTorch\n",
    "    )\n",
    "\n",
    "train_encodings = encode_texts(train_data['text'].tolist(), max_length=128)\n",
    "val_encodings = encode_texts(val_data['text'].tolist(), max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769, 7444,  ...,    0,    0,    0],\n",
       "        [ 101,  100, 3918,  ...,    0,    0,    0],\n",
       "        [ 101,  872, 5543,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 5543, 1415,  ...,    0,    0,    0],\n",
       "        [ 101, 2769, 2682,  ...,    0,    0,    0],\n",
       "        [ 101, 5543, 1415,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(np.unique(train_data['label']))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at F:/code/self/bert_class/hgmodel/bert_base_chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at F:/code/self/bert_class/hgmodel/bert_base_chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(model_path, num_labels=num_labels)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "# model=model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch dataset class\n",
    "class TextClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}  # No need to convert to tensor here, as they are already tensors\n",
    "        item['labels'] = torch.tensor(self.labels[idx])  # Convert labels to tensor\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labe2index_dict={'å›¾æ¨¡æ€æ„å›¾':0, 'è¥é”€æ–‡æ¡ˆæ’°å†™':1, 'è¾¾äººè¥é”€å’¨è¯¢':2, 'è¡Œä¸šè¥é”€å’¨è¯¢':3, 'ä¸Šä¸€è½®æ„å›¾':4, 'å“ç‰Œè¥é”€å’¨è¯¢':5, 'æ–‡æ¡ˆæ’°å†™':6,'IDK':7}\n",
    "# index2labels_dict={1:'å›¾æ¨¡æ€æ„å›¾', 2:'è¥é”€æ–‡æ¡ˆæ’°å†™', 3:'è¾¾äººè¥é”€å’¨è¯¢', 4:'è¡Œä¸šè¥é”€å’¨è¯¢', 5:'ä¸Šä¸€è½®æ„å›¾', 6:'å“ç‰Œè¥é”€å’¨è¯¢', 7:'æ–‡æ¡ˆæ’°å†™',7:'IDK'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laebl2index(label):\n",
    "    return labe2index_dict[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# åˆ›å»º PyTorch æ•°æ®é›†ç±»\n",
    "class TextClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = [laebl2index(item) for item in labels]\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}  # è¿”å›ç¼–ç çš„å¼ é‡\n",
    "        item['labels'] = torch.tensor(int(self.labels[idx]))  # ç¡®ä¿æ ‡ç­¾ä¸ºæ•´æ•°\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TextClassificationDataset(train_encodings, train_data['label'].tolist())\n",
    "val_dataset = TextClassificationDataset(val_encodings, val_data['label'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 101, 2769, 7444, 6206,  711,  671, 3621, 3173, 4638, 1265, 1966, 1501,\n",
       "         3066, 1091,  671, 5063, 3173, 7319, 4943,  816,  934, 6370,  511,  102,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(6)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IDK', 'ä¸Šä¸€è½®æ„å›¾', 'å“ç‰Œè¥é”€å’¨è¯¢', 'å›¾æ¨¡æ€æ„å›¾', 'æ–‡æ¡ˆæ’°å†™', 'è¥é”€æ–‡æ¡ˆæ’°å†™', 'è¡Œä¸šè¥é”€å’¨è¯¢',\n",
       "       'è¾¾äººè¥é”€å’¨è¯¢'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = np.unique(train_data['label'])\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\49262\\miniconda3\\envs\\bertv01\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1016\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 381\n",
      "  Number of trainable parameters = 102273800\n",
      " 13%|â–ˆâ–        | 51/381 [00:09<00:46,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8475, 'learning_rate': 4.343832020997376e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 101/381 [00:16<00:39,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1508, 'learning_rate': 3.6876640419947505e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 127/381 [00:20<00:35,  7.15it/s]***** Running Evaluation *****\n",
      "  Num examples = 113\n",
      "  Batch size = 2\n",
      "                                                 \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 127/381 [00:21<00:35,  7.15it/s]Saving model checkpoint to ./results\\checkpoint-127\n",
      "Configuration saved in ./results\\checkpoint-127\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.011108942329883575, 'eval_accuracy': 1.0, 'eval_runtime': 0.7548, 'eval_samples_per_second': 149.717, 'eval_steps_per_second': 75.521, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-127\\pytorch_model.bin\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 151/381 [00:26<00:32,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0884, 'learning_rate': 3.0314960629921263e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 201/381 [00:33<00:25,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0931, 'learning_rate': 2.3753280839895015e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 251/381 [00:40<00:18,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0653, 'learning_rate': 1.7191601049868766e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 254/381 [00:40<00:18,  6.93it/s]***** Running Evaluation *****\n",
      "  Num examples = 113\n",
      "  Batch size = 2\n",
      "                                                 \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 254/381 [00:41<00:18,  6.93it/s]Saving model checkpoint to ./results\\checkpoint-254\n",
      "Configuration saved in ./results\\checkpoint-254\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.008972665295004845, 'eval_accuracy': 1.0, 'eval_runtime': 0.7038, 'eval_samples_per_second': 160.551, 'eval_steps_per_second': 80.986, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-254\\pytorch_model.bin\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 301/381 [00:50<00:11,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0137, 'learning_rate': 1.062992125984252e-05, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 351/381 [00:57<00:04,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0594, 'learning_rate': 4.068241469816273e-06, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 381/381 [01:01<00:00,  7.25it/s]***** Running Evaluation *****\n",
      "  Num examples = 113\n",
      "  Batch size = 2\n",
      "                                                 \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 381/381 [01:02<00:00,  7.25it/s]Saving model checkpoint to ./results\\checkpoint-381\n",
      "Configuration saved in ./results\\checkpoint-381\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0028565553948283195, 'eval_accuracy': 1.0, 'eval_runtime': 0.7178, 'eval_samples_per_second': 157.417, 'eval_steps_per_second': 79.405, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-381\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-127 (score: 1.0).\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 381/381 [01:04<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 64.8017, 'train_samples_per_second': 47.036, 'train_steps_per_second': 5.879, 'train_loss': 0.1738904350073006, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=381, training_loss=0.1738904350073006, metrics={'train_runtime': 64.8017, 'train_samples_per_second': 47.036, 'train_steps_per_second': 5.879, 'train_loss': 0.1738904350073006, 'epoch': 3.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# æ¨¡å‹å’Œè®­ç»ƒå‚æ•°\n",
    "from transformers import Trainer, TrainingArguments\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy='epoch',  # è¯„ä¼°ç­–ç•¥\n",
    "    save_strategy='epoch',        # ä¿å­˜ç­–ç•¥è®¾ç½®ä¸º epoch\n",
    "    load_best_model_at_end=True,  # å…è®¸åœ¨ç»“æŸæ—¶åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "    metric_for_best_model='accuracy',\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics  # ä¼ é€’è‡ªå®šä¹‰çš„åº¦é‡å‡½æ•°\n",
    "\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'å›¾æ¨¡æ€æ„å›¾': 0,\n",
       " 'è¥é”€æ–‡æ¡ˆæ’°å†™': 1,\n",
       " 'è¾¾äººè¥é”€å’¨è¯¢': 2,\n",
       " 'è¡Œä¸šè¥é”€å’¨è¯¢': 3,\n",
       " 'ä¸Šä¸€è½®æ„å›¾': 4,\n",
       " 'å“ç‰Œè¥é”€å’¨è¯¢': 5,\n",
       " 'æ–‡æ¡ˆæ’°å†™': 6,\n",
       " 'IDK': 7}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labe2index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 3\n",
      "  Batch size = 2\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 50.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ç¼–ç æµ‹è¯•æ•°æ®\n",
    "test_texts = [\"è‹¹æœå…¬å¸åœ¨2024å¹´çš„ç¬¬ä¸€å­£åº¦è¥é”€æ´»åŠ¨æ•ˆæœå¦‚ä½•ï¼Ÿ\", \n",
    "              \"ä½ èƒ½å¸®æˆ‘æƒ³ä¸€ä¸ªæœ‰åˆ›æ„çš„å¹¿å‘Šsloganå—ï¼Ÿ\",\n",
    "              \"æˆ‘éœ€è¦ä¸€ä»½æ´»åŠ¨å…¨æ¡ˆï¼Œç”¨äºæˆ‘ä»¬å³å°†ä¸¾åŠçš„å“ç‰Œæ´»åŠ¨ã€‚\"]\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†\n",
    "class TextClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: tensor[idx] for key, tensor in self.encodings.items()}\n",
    "\n",
    "# åˆå§‹åŒ–æµ‹è¯•é›†\n",
    "test_dataset = TextClassificationDataset(test_encodings)\n",
    "\n",
    "# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# è·å–é¢„æµ‹ç»“æœ\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "# è¾“å‡ºé¢„æµ‹ç»“æœ\n",
    "print(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertv01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
